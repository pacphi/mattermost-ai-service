spring:
  application:
    name: Mattermost AI Service

  httpclient5:
    pool:
      default-connection-config:
        socket-timeout: PT10M

  mvc:
    async:
      request-timeout: ${SPRING_MVC_ASYNC_REQUEST_TIMEOUT:-1}

  threads:
    virtual:
      enabled: true

management:
  info:
    build:
      enabled: true
    git:
      mode: FULL
    java:
      enabled: true
    os:
      enabled: true
  endpoint:
    health:
      show-details: ALWAYS
    metrics:
      access: unrestricted
    prometheus:
      access: unrestricted
    env:
      access: unrestricted
      show-values: ALWAYS
    configprops:
      access: unrestricted
      show-values: ALWAYS
  endpoints:
    web:
      exposure:
        include: info,health,metrics,scheduledtasks,loggers,prometheus,sbom
  tracing:
    sampling:
      probability: 1.0

server:
  tomcat:
    max-swallow-size: -1

mattermost:
  base-url: ${MATTERMOST_BASE_URL:http://localhost:8065}
  credentials:
    username: ${MATTERMOST_USERNAME:mmadmin}
    password: ${MATTERMOST_PASSWORD:mmp@ssw0rd}
admin:
  url: ${mattermost.base-url}
channels:
  url: ${mattermost.base-url}
files:
  url: ${mattermost.base-url}
posts:
  url: ${mattermost.base-url}
preferences:
  url: ${mattermost.base-url}
teams:
  url: ${mattermost.base-url}
users:
  url: ${mattermost.base-url}
webhooks:
  url: ${mattermost.base-url}

---

spring:
  config:
    activate:
      on-profile: groq-cloud
    import: "${SPRING_CONFIG_IMPORT:optional:file:./config/creds.yml}"

  ai:
    openai:
      base_url: ${OPENAI_BASE_URL:https://api.groq.com/openai}
      chat:
        options:
          model: ${CHAT_MODEL:llama-3.3-70b-versatile}
      embedding:
        base_url: ${EMBEDDING_BASEURL:https://api.openai.com}
        options:
          model: ${EMBEDDING_MODEL:text-embedding-ada-002}

---

spring:
  config:
    activate:
      on-profile: openai
    import: "${SPRING_CONFIG_IMPORT:optional:file:./config/creds.yml}"

  ai:
    openai:
      audio:
        speech:
          options:
            # Supported formats are: mp3, opus, aac, flac, wav, and pcm
            response-format: mp3
            # Available options are: alloy, echo, fable, onyx, nova, and shimmer
            voice: nova
            # The speed of the voice synthesis. The acceptable range is from 0.25 (slowest) to 4.0 (fastest).
            speed: 1.0f
        transcription:
          options:
            prompt: "Transcribe the audio"
            # @see https://docs.oracle.com/javase/8/docs/api/java/util/Locale.html#getISOLanguages--
            language: en
            # The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt
            response-format: vtt
      chat:
        options:
          model: ${CHAT_MODEL:gpt-4o-mini}
      embedding:
        options:
          model: ${EMBEDDING_MODEL:text-embedding-ada-002}

---

spring:
  config:
    activate:
      on-profile: ollama

  autoconfigure:
    exclude: org.springframework.ai.autoconfigure.openai.OpenAiAutoConfiguration

  ai:
    ollama:
      base-url: ${OLLAMA_BASE_URL:http://localhost:11434}
      chat:
        options:
          model: ${CHAT_MODEL:mistral}
          num-ctx: ${CHAT_MODEL_CONTEXT_LENGTH:32768}
          truncate: false
      embedding:
        options:
          model: ${EMBEDDING_MODEL:nomic-embed-text}

---

spring:
  config:
    activate:
      on-profile: chroma

  ai:
    vectorstore:
      chroma:
        initialize-schema: true

---

spring:
  config:
    activate:
      on-profile: pgvector

  datasource:
    driver-class-name: ${SPRING_DATASOURCE_DRIVER_CLASS_NAME:org.postgresql.Driver}
    url: ${SPRING_DATASOURCE_URL:jdbc:postgresql://localhost:5432/pgvector}
    username: ${SPRING_DATASOURCE_USER:postgres}
    password: ${SPRING_DATASOURCE_PASSWORD:postgres}

  ai:
    vectorstore:
      pgvector:
        initialize-schema: true
        index-type: HNSW
        distance-type: COSINE_DISTANCE
        dimensions: ${SPRING_AI_VECTORSTORE_PGVECTOR_DIMENSIONS:1536}

---

spring:
  config:
    activate:
      on-profile: redis

  ai:
    vectorstore:
      redis:
        uri: ${SPRING_REDIS_URI:redis://localhost:6379}
        initialize-schema: true

---

spring:
  config:
    activate:
      on-profile: weaviate

  ai:
    vectorstore:
      weaviate:
        host: ${WEAVIATE_HOST:localhost:8088}
        scheme: ${WEAVIATE_SCHEME:http}
        initialize-schema: true
          
---

spring:
  config:
    activate:
      on-profile: dev

  ai:
    ollama:
      init:
        pull-model-strategy: always
        timeout: 15m
        max-retries: 3
        keep_alive: 15m
    vectorstore:
      pgvector:
        remove-existing-vector-store-table: true

debug: true

management:
  endpoints:
    web:
      exposure:
        include: "*"

logging:
  level:
    me.pacphi: TRACE
    org.springframework: DEBUG
    com.fasterxml.jackson: TRACE
